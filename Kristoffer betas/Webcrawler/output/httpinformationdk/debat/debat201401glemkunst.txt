Glem kunstig intelligens, men frygt kunstig idioti
Maskiner er gode til visse ting og rimelige til andre, men de kan ikke for alvor gøre os klogere på hinanden eller på os selv


Store, ja ufattelige talstørrelser dukker gerne op i samtaler om computere. Har du for eksempel hørt om exabyten – en enhed for bitmængder, der måles i et 1-tal efterfulgt af 18 nuller? Eller hvad med petafloppet – en quadrillion beregninger gennemført på ét sekund. Under vores livs overflade bølger et informationhav, fra hvis dybder svar og optimeringer undertiden stiger op som vidunderlige søuhyrer. Dette er big datas for tiden så omtalte rige: De indtil i dag usete mængder af information, der genereres i hidtil uset tempo og i hidtil usete variationer.Fra partikelfysik og intelligente søgninger til sociale mediefølelser høster vi fordele over en stadig bredere vifte af områder. Vi bombarderes med informationer hinsides enhver mæthedsgrænse, mens talstørrelserne antager stadig mere astronomisk proportion. Men forsømmer vi at forholde os til det grundlæggende: Hvad er maskiner gode til, hvad er de mindre gode til? Hvornår er deres svar ubrugelige?Tag nu katte: At lære en computer at genkende katte har vist sig umådeligt svært. I 2012 fodrede Google en specialbygget supercomputer med 10 millioner kattebilleder (disse findes i rigelige mængder på nettet). Håbet var, at big data-alkymien kunne gøre for billedegenkendelse, hvad den har gjort for maskinoversættelse: At en algoritme ud fra en passende stor mængde eksempler kunne lære sig selv at komme med tilnærmelsvis korrekte svar på spørgsmålet: »Hvad er det«?Teknologiens kapitulationMen katte viste sig vanskeligere end ord. Selv om systemet lærte at opstille et sæt grove parametre for ’kattehed’, måtte det i sidste ende kapitulere over for variationerne i størrelse, placering, indstilling og kompleksitet. Selv da det blev udvidet til at omfatte analyse af 20.000 potentielle objektkategorier, lykkedes identifikationen kun med 15,8 procents nøjagtighed: en markant forbedring, men næppe et nyt digitalt daggry.Også på andre områder kan overmodige menneske-maskine-kombinationer være spektakulært unøjagtige. Som superstatistiker Nate Silver bemærker i sin bog fra 2012, The Signal and the Noise, har mange dataknuser-modeller et elendigt præstationsniveau, når det gælder om at få ret i forudsigelser, og beklageligvis indser modellernes udviklere først dette, når det allerede er for sent.»I hele discipliner har afgørende forudsigelser slået fuldstændig fejl, ofte med store omkostninger for samfundet«, noterer Silver og henviser bl.a. til biomedicinsk forskning, national sikkerhed, finansiel og økonomisk modellering, statskundskab og seismologi. A-kraftværket Fukushima blev konstrueret for at kunne modstå det formodet værste scenario. I stedet fik vi en afsløring af, hvor tragisk kløften kan være mellem ekspertmodellernes versioner af ’værste’ og virkelighedens ditto.Fordrejer virkelighedenAt identificere katte har ikke så meget at gøre med at forudsige fremtiden. Men der et fællestræk på spil her: Den informationsprocessering, som begge aktiviteter bygger på, er ikke noget, vi er i stand til at forklare, hverken til maskiner eller over for os selv.Det ville ikke være et problem, hvis alle databehandlings-aktioner i lighed med Googles kattegenkendelsesøvelse var rene eksperimenter, med klare kriterier for fiasko, succes og trinvise forbedringer. I stedet tenderer banaliserende fraser som ’big data’ imod at skjule et semantisk fupnummer, hvor de resultater, systemet genererer, bliver forvekslet med en troværdig repræsentation af verden – eller værre: en besnærende forudsigelig erstatning for den. Hver eneste byte data i verden er produceret, ikke fundet. Og produceret efter metoder med indbygget virkelighedsfordrejning.Når Facebook udfritter mig om, hvad jeg ’synes godt om’, sker det ud fra den forhåndsantagelse, at jeg forholder mig til verden på én af to måder – jeg kan lide noget eller er ligeglad. Når Facebook akkumulerer resultaterne af mine og en milliard andres likes, opstår der i teorien forunderlige nye indsigter. Desværre bygger de på en totalt endimensionel præferencemodel, der muligvis kan skabe rentabel profilering med henblik på markedsføring, men er elendig til at udbygge vores forståelse af den menneskelige bevidsthed eller af den konkrete personlighed.Kunstig idiotiAlle målinger bygger på valg: Hvad skal medtages, hvad skal udelukkes? Hvis en computer en dag skulle få lært sig selv at genkende billeder af katte med absolut nøjagtighed, ville den så vide, hvad en kat var? Kun hvis vi omdefinerer katte til være tavse, ubevægelige, lugtfrie sekvenser af informationer, der danner to-dimensionelle billeder. Hvis en computer kunne lære sig at identificere dig, kære læser, med absolut nøjagtighed ud fra de digitale spor, du afsætter via din sociale medietilstedeværelse, telefonopkald og bankaktiviteter, ville den så vide, hvad det vil sige at være dig? Kun hvis du omdefinerer din person til at være en serie af sporbare datasekvenser, som uophørligt overvåges af maskiner. Hvilket selvfølgelig kan lyde som en fremragende idé for visse mennesker.Big datas største illusion er, at informationer på nogen måde kan skilles fra livet. ’Personlige data’ lyder så meget mindre personligt end de ting, det omfatter: samtaler, møder, rejser, ejendele, indtjening, parforhold, overbevisninger, selvudfoldelse. Men der er intet sted, hvor disse data ender, og det virkelige os begynder. Som computerentusiaster påpeger, er 90 procent af alle data i dag kun produceret inden for de seneste få år. Intet tyder på, at vi skulle være blevet ni gange klogere end alle andre, der har levet, for alt, der kan bygges på en milliard dårlige antagelser, er virkeligt massive og massivt elendige svar.Derfor bør vi glemme alt om kunstig intelligens – i big datas fagre nye verden er det kunstigt idioti, vi må tage os i agt for.Tom Chatfield er britisk teknologikritiker© The Guardian og InformationOversat af Niels Ivar Larsen
