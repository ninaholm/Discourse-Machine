Kunsting intelligens truer menneskets fremtid
Ifølge professor Stephen Hawking er vi ved at sætte vores egen eksistens på spil: Superintelligente computere vil ikke være begrænset af biologisk evolution, men vil kunne perfektionere sig i det uendelige med stadig stigende hast – og hvilken plads bliver der så tilbage til mennesker?


 Eksperterne dækker en skala fra A til B og er stort set enige: Kunstig intelligens (AI) kan gøre det af med den menneskelige civilisation.
Expert A er Elon Musk, universalgeni og iværksætter, medstifter af PayPal, producent af Teslas elbiler, skaber af Space X, den første rent privat drevne virksomhed, der har specialiseret sig i at sende rumfartøjer i kredsløb, og meget andet.
»Vi bliver nødt til at være uhyre forsigtige i vores omgang med kunstig intelligens,« sagde han i oktober til et publikum ved Massachusetts Institute of Technology. »Hvis jeg skal gætte på, hvad der repræsenterer den største eksistentielle trussel mod menneskeheden er, vil jeg nok sige AI.«
Musk advarede AI-ingeniørerne om faren ved at skabe robotter, der vil kunne herske over verden. Ja, han gjorde sig også til talsmand for, at lovgivere skal oprette en tilsynsmyndighed »på nationalt og internationalt plan«, der kan monitorere AI-udviklernes arbejde, »bare for at sikre os, at vi ikke kommer til at gøre noget meget dumt«.
Ekspert B er Stephen Hawking, verdens mest berømte teoretiske fysiker og forfatter til den bedst sælgende ulæste bog nogensinde, A Brief History of Time. Han har en hjerne på størrelse med Danmark, og sidste mandag udtalte han til BBC, at »udviklingen af fuld kunstig intelligens kan indvarsle den menneskelige arts undergang«.
Hawking har en motorisk neuronsygdom, der tvinger ham til at tale ved hjælp af en kunstig talegenerator. Den nye version af denne, som han netop har fået leveret af producenten Intel, tager ved lære af, hvordan professor Hawking tænker, og foreslår selv de ord, den tror, han vil bruge i næste omgang. Der er tale om en tidlig form for AI, så derfor spurgte BBC-intervieweren ham naturligvis om, hvordan han så denne teknologis fremtid.
En virkelig intelligent maskine, advarede Hawking, »ville selv erobre initiativet og omdesigne sig selv i stadig mere forfinede udgaver og med stadig kortere intervaller. Mennesker, hvis udvikling er begrænset af den meget langsommere biologiske evolution, vil slet ikke kunne konkurrere og vil derfor blive afløst«. Så vær meget, meget forsigtig.
Koldt vand i blodet
Musk og Hawking har næsten 50 års populærkultur bag frygten for, at en ondartet AI skal tage kontrol over mennesker (hvis vi regner HAL i Rumrejsen år 2001 for det første eksempel), mens forestillingen om en supercomputer, der opnår bevidsthed og øjeblikkeligt sætter gang i en udryddelseskrig mod menneskeheden, er godt 30 år gammel (’Skynet’ i Terminator-filmene).
Siden kom The Matrix, Blade Runner og lignende variationer over temaet. For respektable tænkere har det taget lidt længere tid at komme på omgangshøjde med al denne fiktionsparanoia, men nu er de ved at være der. Lad os imidlertid slå koldt vand i blodet, for fuld AI med kapaciteter svarende til den menneskelige hjerne eller derover ligger endnu over to eller tre årtier ude i fremtiden, så endnu burde der være god tid til at tænke over, hvordan vi skal håndtere denne teknologi.
Risikoen for, at virkelig intelligente maskiner, som hverken skal fodres eller aflønnes, med tiden kommer til at overtage alle de velbetalte jobs – læger, piloter, revisorer mv. – er reel, ja, muligvis er denne udvikling uafvendelig. Men en katastrofe vil det kun være, hvis vi ikke evner at nyindrette vores kulturelle livsform, således at den kommer til at rumme en hel del mere fritid, og omstrukturere vores økonomi, så den fordeler rigdom efter andre kriterier end som belønning for arbejde.
Et sådant samfund kan meget vel blive et sted, hvor intelligente maskiner får ’rettigheder’, men det er nu ikke det, som fortrinsvis bekymrer skeptikerne. Deres frygt er, at maskiner, der har opnået bevidsthed, vil se mennesket som en trussel (fordi vi vil kunne slukke for dem – i det mindste indtil videre), og at de derfor vil søge at kontrollere os eller endda fjerne os helt. Dette er ’Skynet’-scenariet, men det er ikke videre realistisk.
Moralsk sans
Den frelsende nåde i virkelighedens scenarie er, at AI ikke vil komme på én gang, som når man trykker på en kontakt. Den vil blive opbygget gradvis over årtier, hvilket giver os tid til at indkode en form for moralsk fornuft ind i den grundlæggende programmering, lidt ligesom den moral de fleste mennesker er født med. (En integreret moral er en stor evolutionær fordel for en social art).
Vores moralske sans garanterer ganske vist ikke, at vi altid opfører sig godt, men den er helt sikkert en hjælp. Og når vi er ansvarlige for designet, vil der ikke være tale om blind evolution – vi vil kunne gøre det bedre. Her kan vi gå ud fra Isaac Asimovs Robotikkens tre love, som denne sciencefiction-mester formulerede for 72 år siden.
Første Lov: En robot må ikke skade et menneske eller ved passivitet tillade, at et menneske kommer til skade.
Anden Lov: En robot skal adlyde de ordrer, som mennesker giver, undtagen hvis disse ordrer er i modstrid med Første Lov.
Tredje Lov: En robot skal beskytte sin egen eksistens, så længe en sådan beskyttelse ikke er i modstrid med Første Lov eller Anden Lov.
Ikke en dårlig start, men i sidste ende vil det blive et stridsemne blandt fremtidens mennesker, hvorvidt selvbevidste maskiner for evigt skal fastholdes i slaveri. Tricket må være at finde en måde at indlejre den moralske sans så dybt i programmeringen, at den ikke kan omgås.
Som Googles direktør for teknik, Ray Kurzweil, har anført, kan det imidlertid være svært at skrive et algoritmisk moralkodeks, som er stærkt nok til at begrænse og inddæmme en super-intelligent software.
Vi har sikkert et par årtier til at arbejde på dette, men da vi kommer til at forfølge dette projekt – hele vores civilisations etos kræver det – må vi hellere se at komme i gang.
© Gwynne Dyer og Information Oversat af Niels Ivar Larsen

