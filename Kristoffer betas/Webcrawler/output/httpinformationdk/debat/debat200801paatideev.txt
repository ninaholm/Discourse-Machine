Det er på tide at evaluere Bertel Haarder
Evalueringen af de første nationale it-test i folkeskolen viser, at der er så store problemer med kvaliteten, at en ansvarlig undervisningsminister straks burde udskyde videre test
De nye nationale test til 600.000 danske skoleelever blev prøvekørt af af undervisningsminister Bertel Haarder (V). Men at dømme efter den første evaluering af testene, kunne de godt trænge til en ekstra finpudsning.


 "Der skal en hel del justeringer og ændringer til - men det kan lade sig gøre," sagde Martin Isenbecker, direktør fra Skolestyrelsen, i en pressemeddelelse den 29. oktober 2007, da den første evaluering af funktionaliteten af de nationale it-test var afsluttet med rapporten fra det såkaldte review-panel. 
Evalueringen vedrørte den første version af de tre test i dansk/læsning (8. klasse), matematik (6. klasse) og fysik/kemi (8. klasse), der blev gennemført i maj-juni 2007.
Og direktørens udsagn var ikke en overdrivelse - for at sige det mildt. For en mere kritisk evaluering skal man lede længe efter - og givetvis forgæves, når samtidig review-panelets udpegning og sammensætning haves for øje. Konsortiet med COWI A/S i spidsen, der udviklede de nationale test, og Undervisningsministeriet udpegede nemlig samtlige panelets 10 medlemmer. 
Danmarks Lærerforening fik f.eks. ikke mulighed for at udpege et medlem. Og ikke nok hermed. Samtlige 10 medlemmer havde enten været med til at udvikle testene for konsortiet eller havde rådgivet Undervisningsministeriet. Så det var næppe de mest kritiske, der var repræsenteret i panelet. Og ikke desto mindre er panelets rapport, De nationale it-baserede test i folkeskolen, der i bedste managementstil er sammenskrevet af konsulentfirmaet Devoteam Consulting A/S med udgangspunkt i panelets undersøgelser og drøftelser, meget kritisk.
Det betyder ikke, at der ikke omtales positive forhold. Indledningsvis opridses f.eks. de muligheder, som it engang kan give for at udvikle og teste elevers færdigheder. 
Der nævnes syv vigtige læringsprocesser fra konkret viden til mere og mere komplekse processer som bl.a. evnen til at analysere og syntetisere (sammenfatte/sammendrage). Og det er da meget muligt og endda sandsynligt, at sådanne muligheder engang vil kunne implementeres. Men panelet undlader dog ikke umiddelbart efter opremsningen af de syv læringsprocesser at nævne, at de test, der blev anvendt i maj-juni 2007, helt overvejende vedrørte det første og mest enkle område: tilstedeværelse af konkret viden, dvs. paratviden. Derfor er det vanskeligt at undgå et indtryk af, at disse positive muligheder mest af alt opregnes for at muliggøre, at de efterfølgende meget kritiske bemærkninger ikke virker for voldsomme og dermed kunne risikere at sætte en stopper for dette kostbare, hovedkulse og ikke mindst meget prestigefyldte projekt.
It kan ikke stå alene
I vurderingen af obligatoriske nationale test er det vigtigt at bemærke, at det endnu ikke er dokumenteret, at de forbedrer skoleelevernes præstationer, jvf. f.eks. OECD's PISA-undersøgelser. Bl.a. anvender topscorerlandet i PISA-undersøgelserne, Finland, ikke sådanne test. Hvis nationale obligatoriske test alligevel ønskes gennemført, er det centralt at forholde sig til, om det væsentligste testes. Det er ikke tilfældet med et paratvidensystem som det danske. 
Review-panelet anfører herom: 
"En klar begrænsning er, at it i den form, der findes i dag, ikke kan vurdere sproglige kommunikative kompetencer, kreativitet og originalitet, evne til samarbejde og mere personlige kompetencer. Derfor kan - og skal - it ikke stå alene i vurderingen af kompetencer, men må være et supplement til andre former for vurdering." 
Men Review-panelet anfører også andre meget væsentlige problemer i tilknytning til den valgte form for it-test:
"Som grundlag for udviklingen af opgavebanken er der blandt fagets trinmål udvalgt de trinmål eller dele heraf, der egner sig til it-baserede test."
"Kravet om, at de nationale test skal give en valid og reliabel indplacering af eleverne på en en-dimensional skala (inden for hvert profilområde), indebærer i sig selv den begrænsning, at kun de færdigheder, der lader sig indplacere på en og samme skala, kan indgå i testen. Dermed udelukkes måling af en række af mulige andre færdigheder hos eleven, og dermed reduceres til en vis grad testenes værdi som diagnostisk test."
Men selv denne til paratviden begrænsende testform m.v. blev på ingen måde løst.
Hovedproblemet inden for det valgte, snævre område var mangel på opgaver. Panelet vurderede, at antallet af opgaver som minimum må "tredobles for at leve op til de oprindelige forudsætninger". Det manglende antal paratvidensopgaver betød bl.a., at "afkodning", et af de tre profilområder, ikke kunne testes i dansk/læsning. Det var ligeledes tilfældet med "tal og algebra" i matematik. Da spørgsmålene i to af de tre profilområder i fysik/kemi i realiteten testede det samme, var det således kun få af fagenes områder, der kunne testes, og en række for fagene fastsatte trin- og slutmål var ikke ordentligt repræsenteret i testspørgsmålene.
Usikker rangordning
Hertil kom, at kun halvdelen af det i øvrigt alt for lille antal opgaver var selvstændige. 
Den anden halvdel af opgaverne var varianter af allerede anvendte opgaver. De elever, der fik stillet variantopgaver, kunne i besvarelsen heraf drage fordel af tidligere svar. Da hyppigheden af variantopgaver varierede fra elev til elev, reducerede det yderligere validiteten af testene. 
Et tilsvarende problem knyttet til det beskedne antal opgaver var og er, at lærerne som følge heraf får et relativt godt kendskab til de opgaver, som eleverne vil møde. Det var ikke et problem, hvis det ikke drejede undervisningen i retning af at være rettet mod besvarelsen af disse meget specifikke spørgsmål. Men det kan, som det også vides fra andre lande, og som review-panelet fremhæver, ikke undgås.
De mange problemer i maj-juni 2007-testene, hvoraf kun en del er anført her, fik panelet til at anføre, at der er "en stor risiko for fejlklassifikationer på dygtighedsskalaen med fem trin. I værste fald kan det være tilfældigt, om en elev indplaceres på trin to eller trin fire på dygtighedsskalaen (1-2-3-4-5-skalaen)".
Usikkerheden har endvidere været så stor, at skolerne kun i begrænset omfang har kunnet rangordnes, selv om det er normen i test som f.eks. PISA-test.
Gal tidsmæssig placering
Men hermed er det ikke slut. Stort set alle opgaver i dansk/læsning, hvor fokus blev sat på læsning, må nemlig kasseres, idet "overordentlig mange af de stillede opgaver kan karakteriseres som opgaver, der måler elevens indsigt i dansk sprog, litteratur og kultur snarere end som opgaver i læsning." 
Selvom alle de problemer, panelet fremhæver, og hvoraf nogle er fremhævet her, skulle være løst inden næste testomgang i marts-april 2008 for de tilsvarende tre test som i maj-juni 2007, og for de fire nye testfag i maj-juni 2008 (dansk/læsning i 2., 4. og 6. klasse samt matematik, 3. klasse), vil der stadigvæk være afgørende problemer.
Testene har lige fra starten været tidsmæssigt galt placeret, hvis testresultaterne ellers som angivet skal anvendes fremadrettet til "at målrette undervisningen til den enkelte elevs særlige evner". 
Med dette udgangspunkt er det absurd, at testene er placeret i slutningen af skoleåret og ikke i begyndelsen. Absurditeten forstærkes af, at testresultaterne ved lov er gjort fortrolige, således at det kun er elevens lærer i det pågældende fag og skolelederen, der får kendskab hertil, hvis reglerne altså overholdes. Det er jo nemlig langtfra sikkert, at det er samme lærer, der forsætter undervisningen i det testede fag.
Prestige på spil
De problemer, som review-panelet har afdækket, burde efter min vurdering medføre, at en ansvarlig undervisningsminister straks udskyder videre test og først iværksætter disse, når systemet - hvor indskrænket det end måtte være - virker, idet der ikke er udsigt til, at problemerne vil være løst inden næste testomgang. Men det vil dog næppe ske, dertil har undervisningsministeren for meget prestige på spil. 
At vores skoleelever så bruges som prøveklude, må de så affinde sig med. Det er på det seneste endvidere kommet frem, at Skolestyrelsen tillige endnu ikke var klar til at lade landets skoler booke sig ind på de kommende testdage. Dette er blot endnu et synligt tegn på, hvor kriseramt projektet om de nationale it-test er. 
Var det ikke på tide i stedet at evaluere Haarder?
Christen Sørensen er professor ved Institut for Virksomhedsledelse & Økonomi på Syddansk Universitet

